import streamlit as st
import pandas as pd
from io import StringIO
from euriai import EuriaiClient
import requests
from bs4 import BeautifulSoup
import re
import time
import json

# Streamlit page configuration
st.set_page_config(page_title="AWS Certification Exam Help Buddy", layout="wide")
st.title("📚 Exam Help Buddy with LLM-Generated Mock Test")
st.markdown("Upload your study schedule, or take a scenario-based mock test generated by an LLM!")

# Retrieve the API key from Streamlit secrets
try:
    api_key = st.secrets["EURIAI_API_KEY"]
except KeyError:
    st.error("EURIAI_API_KEY not found in Streamlit secrets. Please add it to your secrets.toml or Streamlit Cloud settings.")
    st.stop()

# Initialize the EuriaiClient with Gemini 2.5 Pro Exp
client = EuriaiClient(
    api_key=api_key,
    model="gemini-2.5-pro-exp-03-25"
)

# Step 1: Scrape and Preprocess the Notes from GitHub
def scrape_github_notes(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    content = soup.find('article', class_='markdown-body')
    text = content.get_text(separator=' ') if content else ''
    return text

def preprocess_text(text):
    text = re.sub(r'[#*_-]+', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

github_url = "https://github.com/Furkan-Gulsen/aws-certified-cloud-practitioner-certification-my-notes"
raw_notes = scrape_github_notes(github_url)
processed_notes = preprocess_text(raw_notes)

# Step 2: Generate Scenario-Based Questions Using LLM
@st.cache_data
def generate_mock_questions(num_questions=5):
    prompt = f"""
    You are an expert exam creator for the AWS Certified Cloud Practitioner (CLF-C01) exam. Using the following notes and topics, generate {num_questions} scenario-based multiple-choice questions. Each question should have 4 options, with one correct answer. Provide the question, options, correct answer, and a brief explanation.

    ### Notes:
    {processed_notes}

    ### Topics to Focus On:
    - Cloud Concepts, Digital Transformation
    - Global Infrastructure, Cloud Architecture
    - Shared Responsibility Model, Compute (EC2)
    - Storage Services (S3)
    - Databases & Networking (VPC, RDS)
    - IAM Best Practices, Containers
    - Governance, Serverless, ML & AI
    - Well-Architected Framework, Billing

    ### Format:
    Return the questions in JSON format:
    [
        {{
            "question": "Scenario-based question here",
            "options": ["Option 1", "Option 2", "Option 3", "Option 4"],
            "correct_answer": "Correct Option",
            "explanation": "Brief explanation of the correct answer"
        }},
        ...
    ]
    """
    response = client.generate_completion(
        prompt=prompt,
        temperature=0.7,
        max_tokens=1500
    )
    try:
        questions = json.loads(response)
        return questions
    except json.JSONDecodeError:
        st.error("Failed to parse LLM-generated questions. Please try again.")
        return []

# Step 3: Mock Test Interface
st.subheader("Scenario-Based Real-Time Mock Test")
st.markdown("Take a mock test with LLM-generated questions under timed conditions!")

# Initialize session state for the mock test
if "mock_test_active" not in st.session_state:
    st.session_state.mock_test_active = False
if "current_question" not in st.session_state:
    st.session_state.current_question = 0
if "score" not in st.session_state:
    st.session_state.score = 0
if "answers" not in st.session_state:
    st.session_state.answers = []
if "start_time" not in st.session_state:
    st.session_state.start_time = None
if "mock_questions" not in st.session_state:
    st.session_state.mock_questions = []

# Start the mock test
if st.button("Start Mock Test"):
    st.session_state.mock_questions = generate_mock_questions(num_questions=5)
    if st.session_state.mock_questions:
        st.session_state.mock_test_active = True
        st.session_state.current_question = 0
        st.session_state.score = 0
        st.session_state.answers = []
        st.session_state.start_time = time.time()

# Mock test logic
if st.session_state.mock_test_active and st.session_state.mock_questions:
    total_questions = len(st.session_state.mock_questions)
    question_index = st.session_state.current_question

    if question_index < total_questions:
        question_data = st.session_state.mock_questions[question_index]
        st.write(f"**Question {question_index + 1}/{total_questions}:** {question_data['question']}")
        
        # Timer (30 seconds per question)
        elapsed_time = time.time() - st.session_state.start_time
        time_left = max(0, 30 - (elapsed_time % 30))
        st.write(f"Time left for this question: {int(time_left)} seconds")

        # Multiple-choice options
        user_answer = st.radio("Select your answer:", question_data["options"], key=f"q_{question_index}")

        # Submit answer
        if st.button("Submit Answer"):
            # Grade the answer using the LLM
            prompt = f"""
            Grade the user's answer for the following question:
            Question: {question_data['question']}
            Correct Answer: {question_data['correct_answer']}
            User's Answer: {user_answer}

            Provide a score (0 or 1) and a brief explanation of the grading.
            Format:
            {{
                "score": 1,
                "explanation": "Explanation of the grading"
            }}
            """
            response = client.generate_completion(
                prompt=prompt,
                temperature=0.7,
                max_tokens=300
            )
            try:
                grading = json.loads(response)
                score = grading["score"]
                explanation = grading["explanation"]
            except json.JSONDecodeError:
                score = 1 if user_answer == question_data["correct_answer"] else 0
                explanation = "Default grading: " + ("Correct" if score == 1 else "Incorrect")

            st.session_state.answers.append({
                "question": question_data["question"],
                "user_answer": user_answer,
                "correct_answer": question_data["correct_answer"],
                "explanation": explanation,
                "score": score
            })
            st.session_state.score += score
            st.session_state.current_question += 1
            st.session_state.start_time = time.time()  # Reset timer for next question
            st.experimental_rerun()

    else:
        # End of test
        st.session_state.mock_test_active = False
        st.write("**Mock Test Completed!**")
        st.write(f"Your Score: {st.session_state.score}/{total_questions}")
        st.write("### Feedback:")
        for i, answer in enumerate(st.session_state.answers):
            st.write(f"**Question {i + 1}:** {answer['question']}")
            st.write(f"Your Answer: {answer['user_answer']}")
            st.write(f"Correct Answer: {answer['correct_answer']}")
            st.write(f"Grading Explanation: {answer['explanation']}")
            st.write("---")

        # Reset for a new test
        if st.button("Restart Mock Test"):
            st.session_state.mock_test_active = False
            st.session_state.current_question = 0
            st.session_state.score = 0
            st.session_state.answers = []
            st.session_state.start_time = None
            st.session_state.mock_questions = []
            st.experimental_rerun()

# Existing Exam Help Buddy Code (Schedule Revision)
default_data = """
Date,Day,Study Hours,Video Segment,Topics,Hands-On/Labs,Tips & Tricks,Status
2025-04-26,Sat,5:00:00-2:06:32,Intro, Cloud Concepts, Digital Transformation,SkillBuilder Cloud Essentials lab,Pause every 15 min & write Cornell notes; focus on shared-responsibility model early.,
2025-04-27,Sun,5:2:06:32-3:12:40,Global Infrastructure, Cloud Architecture,Draw global map + 3-tier diagram in AWS Perspective CloudFormation Designer & Cloud9 walkthrough,Memorize Regions vs AZ counts using stories (e.g., 6 AZs in N. Virginia - think 6-pack); create free-tier budget alerts before experimenting. Create a free-tier budget alarm before experimenting; note which services are ‘global’. Compare EC2 purchasing options in a mini-table; memorize Stop vs Terminate behaviour.,
2025-04-28,Mon,3:3:12:40-4:50:13,Management & Developer Tools,,,,
2025-04-29,Tue,3:4:50:13-6:02:37,Shared Responsibility & Compute,Launch EC2, attach IAM role, practice SSH,Compare EC2 purchasing options in a mini-table; memorize Step vs Spot vs Terminate behaviour.,
2025-04-30,Wed,3:6:02:37-6:40:15,Storage Services & Compute,Build S3 static website, enable versioning & lifecycle rules,Know four S3 storage classes & decision points; practice presigned URL demo.,
2025-05-01,Thu,3:6:40:15-7:32:16,Databases & Networking,Create VPC with 2 subnets, launch RDS MySQL AWS Pricing Calculator demo,Draw CIDR blocks on paper; remember VPC default limits (5 VPC/region). Build quick cheat-sheet: On-Demand, Spot, Savings Plan, Dedicated; relate to real bills.,
2025-05-02,Fri,3:7:32:16-8:42:58,EC2 & Pricing Models,,,,
2025-05-03,Sat,5:8:42:58-9:51:00,IAM Best-practices Identity, App Integration, Containers,Fargate Organizations SCP, CloudFormation StackSets, Lambda + API GATEWAY,Associate IAM policy boundaries visually; memorize 3 ECR image scan options.,
2025-05-04,Sun,5:9:51:00-10:44:52,Governance, Provisioning, Serverless Logging, ML & AI,Enable CloudWatch Alarms; Bedrock console demo,Lambda limits: 6 MB env vars, 15 min runtime; draw flow of ORG -> SCP -> Account. Remember difference between CW Logs vs Metrics; recall EMF custom metrics JSON.,
2025-05-05,Mon,3:10:53:33-11:44:41,Well-Architected, TCO, Migration, Billing,COST Explorer & Trusted Advisor deep-dive,Focus on 6 Well-Architected pillars (Security updated 2023); practice Savings Plan calc. Track score per domain, aim > 80%. Re-watch weakest 15 min of video.,
2025-05-06,Tue,3:11:44:41-13:14:58,EXAM PREP practice test,Flash review mind-maps & cheats,Step 8 h; light review only—no new content.,
2025-05-08,Thu,3:—,AWS Official Sample Qs; Final Review,Flash review mind-maps & cheats,Arrive three min early, deep breaths, read each Q twice.,
2025-05-09,Fri,—,EXAM DAY,30-min recall of acronyms & limits,,
2025-05-10,Sat,5:0:00-1:45:00,Exam scope, AI vs ML vs GenAI, AWS AI service stack,Bedrock console tour; create IAM service role; set up free-tier SageMaker Studio domain,Download course PDF slides; create glossary sheet for new acronyms right away. Remember THREE deployment modes mnemonic: Real-Time, Async, Batch -> RAB’; note regional availability.,
2025-05-11,Sun,5:1:45:00-3:45:00,Autopilot, training & deployment options,Run Jumpstart text-classification model; launch Autopilot job on CSV sample; compare real-time vs batch inference,,
2025-05-12,Mon,3:3:45:00-4:35:00,Generative AI Foundations—LLM, options,Create Bedrock Knowledge Base; run a RAG chat with 3-doc S3 corpus,Draw the RAG pipeline boxes on paper; practice phrasing “instruction-context-input-format” prompts.,
2025-05-13,Tue,3:4:35:00-5:25:00,Bedrock Model Zoo—Titan, Claude, Llama 3,Invoke Titan Text and Claude 3 Sonnet via SDK, compare latency max-tokens limits,Build a quick table of context window & multimodal support for each FM; memorize top two limits.,
2025-05-14,Wed,3:5:25:00-6:15:00,Media AI—Transcribe, Translate, Polly, IVS with chat highlights,Transcribe 30-sec MP3 -> translate to ES -> Polly synth voice; pipeline in workflow studio,Limit free tier (Standard vs Medical) and file size quotas; practice closed caption export.,
2025-05-15,Thu,3:6:15:00-7:05:00,Vision AI—Rekognition, Textract, Lookout for Vision,Detect faces + PPE in Rekognition; Textract AnalyzeExpense store receipt sample,Write 5 key confidence score thresholds; remember that Rekognition Custom Labels is separate console.,
2025-05-16,Fri,3:7:05:00-7:55:00,Search & Chat—Kendra, Bedrock, RAG, Lex V2,Index 10-page PDF set in Kendra; build FAQ bot with Lex; test,Associate Kendra index, data source, sync schedule; note on-demand vs provisioned mode costs.,
2025-05-17,Sat,5:7:55:00-9:45:00,Vertical AI—Personalize, Forecast, Fraud Detector, Lookout for Metrics/Equipment,Create Personalize dataset group & solution version; Forecast dataset import wizard,Teach each vertical AI service to a customer story to aid recall; record default data frequency limits.,
2025-05-18,Sun,5:9:45:00-11:30:00,AI Governance & Security; Cost Mgmt; Exam Domain 1–4 deep dive,Enable Bedrock CloudTrail data events; explore SageMaker Model Cards & Guardrails,Memorize GenAI risks (Bias, Hallucination, IP) + mitigation features; snapshot budgets dashboard.,
2025-05-19,Mon,3:—,Practice Exam #1,Mark incorrect Qs by domain; add to ‘weak-spots’ list,Aim 2 75% per domain; re-watch corresponding lecture clips same evening.,
2025-05-20,Tue,3:—,Practice Exam #2 + Second timed test + cheat-sheet consolidation,Create one-pager table: service -> purpose -> key limits -> pricing,Use Feynman technique—explain a hard concept to rubber duck; fill gaps.,
2025-05-21,Wed,—,EXAM DAY—AIF-C01,15 min quick recall sheet; breathing exercise,Use Feynman technique—explain a hard concept to rubber duck; fill gaps & return on edge cases.,
"""

# File uploader for Excel file
uploaded_file = st.file_uploader("Upload your study schedule Excel file", type=["xlsx", "xls"])

# Load data
if uploaded_file is not None:
    df = pd.read_excel(uploaded_file)
    st.success("File uploaded successfully!")
else:
    # Use default data if no file is uploaded
    df = pd.read_csv(StringIO(default_data))
    st.info("Using default study schedule data.")

# Display the original schedule
st.subheader("Original Study Schedule")
st.dataframe(df)

# Button to generate revised schedule
if st.button("Generate Revised Schedule"):
    with st.spinner("Analyzing your schedule and generating a revised plan..."):
        prompt = f"""
        You are an Exam Help Buddy. Below is my study schedule for two exams: AIF-C01 on 2025-05-09 and Exam #2 on 2025-05-21. Analyze the schedule, optimize study hours to prevent burnout, ensure balanced topic coverage, incorporate the tips and labs into the plan, and add short breaks and review sessions. Provide a revised daily schedule with specific tasks and tips for each day leading up to the exams.

        ### Study Schedule:
        {df.to_string(index=False)}

        ### Instructions:
        1. Optimize study hours (e.g., reduce long sessions to 3-4 hours, add 15-min breaks after every 2 hours).
        2. Ensure balanced topic coverage across days, focusing on weaker areas.
        3. Incorporate the 'Tips & Tricks' into daily tasks.
        4. Add short review sessions for key concepts (e.g., 30-min review of previous day's topics).
        5. Output a revised schedule in the format: 'Date, Day, Revised Study Hours, Tasks, Tips'.

        Return the revised schedule as a table in text format.
        """
        try:
            response = client.generate_completion(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1500
            )
            revised_schedule = pd.read_csv(StringIO(response), sep=",")
            st.subheader("Revised Study Schedule")
            st.dataframe(revised_schedule)
            csv = revised_schedule.to_csv(index=False)
            st.download_button(
                label="Download Revised Schedule as CSV",
                data=csv,
                file_name="revised_study_schedule.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"Error generating revised schedule: {str(e)}")

# Add a footer
st.markdown("---")
st.markdown("Built with ❤️ by Exam Help Buddy using Streamlit and Euriai API (Gemini 2.5 Pro Exp).")
